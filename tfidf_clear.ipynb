{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39917705-6d70-411e-8dd0-8ed3ff64f459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.feature_extraction.text import CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d6ed4d0-0bfa-4e8c-9d3a-b7d1f4f0bb59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>username</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>final_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1387917769501515778</td>\n",
       "      <td>2021-04-29 23:52:37+00:00</td>\n",
       "      <td>MaseebAkhter</td>\n",
       "      <td>24.972077</td>\n",
       "      <td>67.064381</td>\n",
       "      <td>rd jumma mubarak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1387914934533513220</td>\n",
       "      <td>2021-04-29 23:41:21+00:00</td>\n",
       "      <td>PolsekPlaju3</td>\n",
       "      <td>-3.190822</td>\n",
       "      <td>104.794609</td>\n",
       "      <td>lawan covid sinergitas tni polri cegah tular c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1387913431865610244</td>\n",
       "      <td>2021-04-29 23:35:22+00:00</td>\n",
       "      <td>irfania_real</td>\n",
       "      <td>31.315389</td>\n",
       "      <td>74.222395</td>\n",
       "      <td>jummah mubarak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1387911958393987075</td>\n",
       "      <td>2021-04-29 23:29:31+00:00</td>\n",
       "      <td>kenny_thok</td>\n",
       "      <td>-2.455096</td>\n",
       "      <td>111.930698</td>\n",
       "      <td>semangat ya neng isolasi pakai sek pondok deri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1387907774441566213</td>\n",
       "      <td>2021-04-29 23:12:54+00:00</td>\n",
       "      <td>kejarirohul</td>\n",
       "      <td>0.902542</td>\n",
       "      <td>100.308263</td>\n",
       "      <td>kamis tanggal april kepala seksi intelijen ari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8109</th>\n",
       "      <td>1536673294782709760</td>\n",
       "      <td>2022-06-14 11:33:58+00:00</td>\n",
       "      <td>StellaSuwardi</td>\n",
       "      <td>-6.297602</td>\n",
       "      <td>106.770437</td>\n",
       "      <td>vaksinasi booster tingkat imunitas varian omic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8110</th>\n",
       "      <td>1536525461077262336</td>\n",
       "      <td>2022-06-14 01:46:31+00:00</td>\n",
       "      <td>natasya_puspa4</td>\n",
       "      <td>-6.364100</td>\n",
       "      <td>106.799599</td>\n",
       "      <td>jokowi menteri waspada hati hati varian omicro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8111</th>\n",
       "      <td>1536515216665899013</td>\n",
       "      <td>2022-06-14 01:05:49+00:00</td>\n",
       "      <td>Agistasyahka</td>\n",
       "      <td>-6.301652</td>\n",
       "      <td>106.974561</td>\n",
       "      <td>sebar virus omicron ba ba cepat banding varian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8112</th>\n",
       "      <td>1536358141377384448</td>\n",
       "      <td>2022-06-13 14:41:39+00:00</td>\n",
       "      <td>Ardi_Wdyto</td>\n",
       "      <td>-7.776581</td>\n",
       "      <td>113.198255</td>\n",
       "      <td>varian omicron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8113</th>\n",
       "      <td>1536251604772745216</td>\n",
       "      <td>2022-06-13 07:38:19+00:00</td>\n",
       "      <td>gemaposID</td>\n",
       "      <td>-6.218042</td>\n",
       "      <td>106.857762</td>\n",
       "      <td>breaking news omicron ba ba resmi deteksi indo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8114 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                       date        username  \\\n",
       "0     1387917769501515778  2021-04-29 23:52:37+00:00    MaseebAkhter   \n",
       "1     1387914934533513220  2021-04-29 23:41:21+00:00    PolsekPlaju3   \n",
       "2     1387913431865610244  2021-04-29 23:35:22+00:00    irfania_real   \n",
       "3     1387911958393987075  2021-04-29 23:29:31+00:00      kenny_thok   \n",
       "4     1387907774441566213  2021-04-29 23:12:54+00:00     kejarirohul   \n",
       "...                   ...                        ...             ...   \n",
       "8109  1536673294782709760  2022-06-14 11:33:58+00:00   StellaSuwardi   \n",
       "8110  1536525461077262336  2022-06-14 01:46:31+00:00  natasya_puspa4   \n",
       "8111  1536515216665899013  2022-06-14 01:05:49+00:00    Agistasyahka   \n",
       "8112  1536358141377384448  2022-06-13 14:41:39+00:00      Ardi_Wdyto   \n",
       "8113  1536251604772745216  2022-06-13 07:38:19+00:00       gemaposID   \n",
       "\n",
       "       latitude   longitude                                        final_tweet  \n",
       "0     24.972077   67.064381                                   rd jumma mubarak  \n",
       "1     -3.190822  104.794609  lawan covid sinergitas tni polri cegah tular c...  \n",
       "2     31.315389   74.222395                                     jummah mubarak  \n",
       "3     -2.455096  111.930698  semangat ya neng isolasi pakai sek pondok deri...  \n",
       "4      0.902542  100.308263  kamis tanggal april kepala seksi intelijen ari...  \n",
       "...         ...         ...                                                ...  \n",
       "8109  -6.297602  106.770437  vaksinasi booster tingkat imunitas varian omic...  \n",
       "8110  -6.364100  106.799599  jokowi menteri waspada hati hati varian omicro...  \n",
       "8111  -6.301652  106.974561  sebar virus omicron ba ba cepat banding varian...  \n",
       "8112  -7.776581  113.198255                                     varian omicron  \n",
       "8113  -6.218042  106.857762  breaking news omicron ba ba resmi deteksi indo...  \n",
       "\n",
       "[8114 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('HasilPreProcess.csv')\n",
    "df\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7adf9df-db14-401f-a2db-f074c30449b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = df.final_tweet.fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45c4002e-fb9e-4e59-9273-3dbe8e171111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                        rd jumma mubarak\n",
       "1       lawan covid sinergitas tni polri cegah tular c...\n",
       "2                                          jummah mubarak\n",
       "3       semangat ya neng isolasi pakai sek pondok deri...\n",
       "4       kamis tanggal april kepala seksi intelijen ari...\n",
       "                              ...                        \n",
       "8109    vaksinasi booster tingkat imunitas varian omic...\n",
       "8110    jokowi menteri waspada hati hati varian omicro...\n",
       "8111    sebar virus omicron ba ba cepat banding varian...\n",
       "8112                                       varian omicron\n",
       "8113    breaking news omicron ba ba resmi deteksi indo...\n",
       "Name: final_tweet, Length: 8114, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b106a22-9ee3-46d5-924c-87c94de8ce5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using Series.values.tolist()\n",
    "col_list = df.final_tweet.values.tolist()\n",
    "# print(col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "540e15d5-074e-45d7-aa58-ad43538e888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate CountVectorizer() \n",
    "cv=CountVectorizer(min_df=300) \n",
    "# this steps generates word counts for the words in your docs \n",
    "word_count_vector=cv.fit_transform(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfdab5c1-d8e8-41e6-b23c-89febad84aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8114, 26)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37728039-c49b-45dc-b109-2f3606db2b7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_tf \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mterms\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\skripsitwit\\lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\skripsitwit\\lib\\site-packages\\pandas\\core\\internals\\construction.py:450\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    448\u001b[0m     index \u001b[38;5;241m=\u001b[39m _extract_index(arrays[\u001b[38;5;241m~\u001b[39mmissing])\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 450\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[43mensure_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# no obvious \"empty\" int column\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing\u001b[38;5;241m.\u001b[39many() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_integer_dtype(dtype):\n",
      "File \u001b[1;32m~\\.conda\\envs\\skripsitwit\\lib\\site-packages\\pandas\\core\\indexes\\base.py:7333\u001b[0m, in \u001b[0;36mensure_index\u001b[1;34m(index_like, copy)\u001b[0m\n\u001b[0;32m   7331\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Index\u001b[38;5;241m.\u001b[39m_with_infer(index_like, copy\u001b[38;5;241m=\u001b[39mcopy, tupleize_cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   7332\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 7333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\skripsitwit\\lib\\site-packages\\pandas\\core\\indexes\\base.py:716\u001b[0m, in \u001b[0;36mIndex._with_infer\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m    715\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*the Index constructor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m--> 716\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m _dtype_obj \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_is_multi:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"maybe_convert_objects\" has incompatible type\u001b[39;00m\n\u001b[0;32m    720\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected\u001b[39;00m\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;66;03m# \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     values \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result\u001b[38;5;241m.\u001b[39m_values)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\skripsitwit\\lib\\site-packages\\pandas\\core\\indexes\\base.py:565\u001b[0m, in \u001b[0;36mIndex.__new__\u001b[1;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m MultiIndex\u001b[38;5;241m.\u001b[39mfrom_tuples(\n\u001b[0;32m    561\u001b[0m             data, names\u001b[38;5;241m=\u001b[39mname \u001b[38;5;129;01mor\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    562\u001b[0m         )\n\u001b[0;32m    563\u001b[0m \u001b[38;5;66;03m# other iterable of some kind\u001b[39;00m\n\u001b[1;32m--> 565\u001b[0m subarr \u001b[38;5;241m=\u001b[39m \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray_tuplesafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;66;03m# with e.g. a list [1, 2, 3] casting to numeric is _not_ deprecated\u001b[39;00m\n\u001b[0;32m    568\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m _maybe_cast_data_without_dtype(\n\u001b[0;32m    569\u001b[0m         subarr, cast_numeric_deprecated\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    570\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\skripsitwit\\lib\\site-packages\\pandas\\core\\common.py:238\u001b[0m, in \u001b[0;36masarray_tuplesafe\u001b[1;34m(values, dtype)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21masarray_tuplesafe\u001b[39m(values: Iterable, dtype: NpDtype \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(values, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(values, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__array__\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m--> 238\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, ABCIndex):\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39m_values\n",
      "\u001b[1;31mTypeError\u001b[0m: 'method' object is not iterable"
     ]
    }
   ],
   "source": [
    "df_tf = pd.DataFrame(index=cv.get_feature_names_out,columns=[\"terms\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccd868cb-0e21-4c9a-9e1e-10358a74ccec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfTransformer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfTransformer()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True) \n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3e09c91-2796-4e11-94fd-41aa52c42509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sakit</th>\n",
       "      <td>2.355116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demam</th>\n",
       "      <td>2.531245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>covid</th>\n",
       "      <td>2.536387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kepala</th>\n",
       "      <td>2.815325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batuk</th>\n",
       "      <td>2.868972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pilek</th>\n",
       "      <td>3.248032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ni</th>\n",
       "      <td>3.416678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ya</th>\n",
       "      <td>3.547844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vaksin</th>\n",
       "      <td>3.576600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>varian</th>\n",
       "      <td>3.591295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diare</th>\n",
       "      <td>3.673533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dah</th>\n",
       "      <td>3.682501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta</th>\n",
       "      <td>3.788863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nak</th>\n",
       "      <td>3.802991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banget</th>\n",
       "      <td>3.833953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>makan</th>\n",
       "      <td>3.850867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tenggorok</th>\n",
       "      <td>3.855140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>badan</th>\n",
       "      <td>3.923827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orang</th>\n",
       "      <td>3.940013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>com</th>\n",
       "      <td>4.071880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kena</th>\n",
       "      <td>4.112592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tu</th>\n",
       "      <td>4.126539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lelah</th>\n",
       "      <td>4.152145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sehat</th>\n",
       "      <td>4.230028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obat</th>\n",
       "      <td>4.230028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sesak</th>\n",
       "      <td>4.294359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           idf_weights\n",
       "sakit         2.355116\n",
       "demam         2.531245\n",
       "covid         2.536387\n",
       "kepala        2.815325\n",
       "batuk         2.868972\n",
       "pilek         3.248032\n",
       "ni            3.416678\n",
       "ya            3.547844\n",
       "vaksin        3.576600\n",
       "varian        3.591295\n",
       "diare         3.673533\n",
       "dah           3.682501\n",
       "delta         3.788863\n",
       "nak           3.802991\n",
       "banget        3.833953\n",
       "makan         3.850867\n",
       "tenggorok     3.855140\n",
       "badan         3.923827\n",
       "orang         3.940013\n",
       "com           4.071880\n",
       "kena          4.112592\n",
       "tu            4.126539\n",
       "lelah         4.152145\n",
       "sehat         4.230028\n",
       "obat          4.230028\n",
       "sesak         4.294359"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print idf values \n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names_out(),columns=[\"idf_weights\"]) \n",
    "# sort ascending \n",
    "df_idf.sort_values(by=['idf_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eca03ee-9193-474a-b0e1-4aa19d3b3901",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_idf_clear = df_idf.drop(['nak','ni','ya','dah','kena','com','banget','tu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b216243f-94cc-4bca-94aa-c82d71f64baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>badan</th>\n",
       "      <td>3.923827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batuk</th>\n",
       "      <td>2.868972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>covid</th>\n",
       "      <td>2.536387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta</th>\n",
       "      <td>3.788863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demam</th>\n",
       "      <td>2.531245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diare</th>\n",
       "      <td>3.673533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kepala</th>\n",
       "      <td>2.815325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lelah</th>\n",
       "      <td>4.152145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>makan</th>\n",
       "      <td>3.850867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obat</th>\n",
       "      <td>4.230028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orang</th>\n",
       "      <td>3.940013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pilek</th>\n",
       "      <td>3.248032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sakit</th>\n",
       "      <td>2.355116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sehat</th>\n",
       "      <td>4.230028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sesak</th>\n",
       "      <td>4.294359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tenggorok</th>\n",
       "      <td>3.855140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vaksin</th>\n",
       "      <td>3.576600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>varian</th>\n",
       "      <td>3.591295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           idf_weights\n",
       "badan         3.923827\n",
       "batuk         2.868972\n",
       "covid         2.536387\n",
       "delta         3.788863\n",
       "demam         2.531245\n",
       "diare         3.673533\n",
       "kepala        2.815325\n",
       "lelah         4.152145\n",
       "makan         3.850867\n",
       "obat          4.230028\n",
       "orang         3.940013\n",
       "pilek         3.248032\n",
       "sakit         2.355116\n",
       "sehat         4.230028\n",
       "sesak         4.294359\n",
       "tenggorok     3.855140\n",
       "vaksin        3.576600\n",
       "varian        3.591295"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_idf_clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d404bc9-20ec-4d3c-b726-8b723a1902c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count matrix \n",
    "count_vector=cv.transform(final) \n",
    "# tf-idf scores \n",
    "tf_idf_vector=tfidf_transformer.transform(count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5838b55-55dc-4947-8f0d-14d90c585a65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (1, 4)\t1.0\n",
      "  (3, 25)\t0.6569247759498295\n",
      "  (3, 3)\t0.7539561252110539\n",
      "  (4, 10)\t0.506141277365855\n",
      "  (4, 4)\t0.4559935163011373\n",
      "  (4, 3)\t0.7320457092544052\n",
      "  (6, 4)\t1.0\n",
      "  (7, 19)\t0.8576387166513539\n",
      "  (7, 4)\t0.5142526924583076\n",
      "  (9, 16)\t0.8408364573032331\n",
      "  (9, 4)\t0.5412892499114943\n",
      "  (10, 25)\t0.6109744111770967\n",
      "  (10, 4)\t0.4367912419588586\n",
      "  (10, 1)\t0.6602451664607911\n",
      "  (12, 25)\t1.0\n",
      "  (13, 19)\t0.6613731337942507\n",
      "  (13, 4)\t0.39656898431690574\n",
      "  (13, 3)\t0.6366463842456267\n",
      "  (14, 4)\t1.0\n",
      "  (15, 4)\t1.0\n",
      "  (16, 4)\t0.5287184280764015\n",
      "  (16, 3)\t0.848797280752253\n",
      "  (17, 4)\t1.0\n",
      "  (18, 4)\t1.0\n",
      "  (19, 4)\t1.0\n",
      "  :\t:\n",
      "  (8096, 24)\t1.0\n",
      "  (8097, 24)\t1.0\n",
      "  (8098, 24)\t1.0\n",
      "  (8099, 24)\t1.0\n",
      "  (8100, 24)\t0.6836334470465906\n",
      "  (8100, 1)\t0.7298255340005557\n",
      "  (8101, 24)\t0.4486816533882153\n",
      "  (8101, 23)\t0.8936916548300187\n",
      "  (8102, 24)\t1.0\n",
      "  (8103, 24)\t0.661462038116428\n",
      "  (8103, 3)\t0.7499786477832958\n",
      "  (8104, 24)\t1.0\n",
      "  (8105, 24)\t0.661462038116428\n",
      "  (8105, 3)\t0.7499786477832958\n",
      "  (8106, 24)\t1.0\n",
      "  (8107, 24)\t1.0\n",
      "  (8108, 24)\t1.0\n",
      "  (8109, 24)\t1.0\n",
      "  (8110, 24)\t0.8168226120033354\n",
      "  (8110, 4)\t0.5768889152341625\n",
      "  (8111, 24)\t0.8362263774767817\n",
      "  (8111, 18)\t0.5483843958502639\n",
      "  (8112, 24)\t1.0\n",
      "  (8113, 24)\t0.8168226120033354\n",
      "  (8113, 4)\t0.5768889152341625\n"
     ]
    }
   ],
   "source": [
    "print(tf_idf_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59072781-0590-409d-a6eb-8a6dc6d3799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = cv.get_feature_names_out() \n",
    "test = list(range(1, 8115))\n",
    "#get tfidf vector for first document \n",
    "first_document_vector=tf_idf_vector\n",
    "#print the scores \n",
    "df = pd.DataFrame(first_document_vector.T.todense(), index=feature_names , columns=test) \n",
    "#df.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "206b1ac7-2cda-467c-800c-693c32855b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7523a97c-bc43-40dc-846d-76847b4987ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>badan</th>\n",
       "      <th>banget</th>\n",
       "      <th>batuk</th>\n",
       "      <th>com</th>\n",
       "      <th>covid</th>\n",
       "      <th>dah</th>\n",
       "      <th>delta</th>\n",
       "      <th>demam</th>\n",
       "      <th>diare</th>\n",
       "      <th>kena</th>\n",
       "      <th>...</th>\n",
       "      <th>orang</th>\n",
       "      <th>pilek</th>\n",
       "      <th>sakit</th>\n",
       "      <th>sehat</th>\n",
       "      <th>sesak</th>\n",
       "      <th>tenggorok</th>\n",
       "      <th>tu</th>\n",
       "      <th>vaksin</th>\n",
       "      <th>varian</th>\n",
       "      <th>ya</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8110</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8111</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.576889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.816823</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8112</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.548384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.836226</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8113</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8114</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.576889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.816823</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      badan  banget  batuk  com     covid  dah  delta  demam  diare  kena  \\\n",
       "8110    0.0     0.0    0.0  0.0  0.000000  0.0    0.0    0.0    0.0   0.0   \n",
       "8111    0.0     0.0    0.0  0.0  0.576889  0.0    0.0    0.0    0.0   0.0   \n",
       "8112    0.0     0.0    0.0  0.0  0.000000  0.0    0.0    0.0    0.0   0.0   \n",
       "8113    0.0     0.0    0.0  0.0  0.000000  0.0    0.0    0.0    0.0   0.0   \n",
       "8114    0.0     0.0    0.0  0.0  0.576889  0.0    0.0    0.0    0.0   0.0   \n",
       "\n",
       "      ...  orang  pilek     sakit  sehat  sesak  tenggorok   tu  vaksin  \\\n",
       "8110  ...    0.0    0.0  0.000000    0.0    0.0        0.0  0.0     0.0   \n",
       "8111  ...    0.0    0.0  0.000000    0.0    0.0        0.0  0.0     0.0   \n",
       "8112  ...    0.0    0.0  0.548384    0.0    0.0        0.0  0.0     0.0   \n",
       "8113  ...    0.0    0.0  0.000000    0.0    0.0        0.0  0.0     0.0   \n",
       "8114  ...    0.0    0.0  0.000000    0.0    0.0        0.0  0.0     0.0   \n",
       "\n",
       "        varian   ya  \n",
       "8110  1.000000  0.0  \n",
       "8111  0.816823  0.0  \n",
       "8112  0.836226  0.0  \n",
       "8113  1.000000  0.0  \n",
       "8114  0.816823  0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "179de276-e12c-410a-a477-7e133874ae0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "lower not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[0;32m      2\u001b[0m tfidf_vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer()\n\u001b[1;32m----> 3\u001b[0m tfidf_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mtfidf_vectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_idf_vector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(cosine_similarity(tfidf_matrix[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m], tfidf_matrix[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m]))\n",
      "File \u001b[1;32m~\\.conda\\envs\\skripsitwit\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2133\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2128\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2129\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2130\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2131\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2132\u001b[0m )\n\u001b[1;32m-> 2133\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2135\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2136\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\skripsitwit\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1388\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1380\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1381\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1382\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1384\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1385\u001b[0m             )\n\u001b[0;32m   1386\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1391\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\skripsitwit\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1275\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1273\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[0;32m   1274\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1275\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1276\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1277\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32m~\\.conda\\envs\\skripsitwit\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:111\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 111\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    113\u001b[0m         doc \u001b[38;5;241m=\u001b[39m tokenizer(doc)\n",
      "File \u001b[1;32m~\\.conda\\envs\\skripsitwit\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:69\u001b[0m, in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m\"\"\"Chain together an optional series of text preprocessing steps to\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03mapply to a document.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    preprocessed string\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lower:\n\u001b[1;32m---> 69\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accent_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m     doc \u001b[38;5;241m=\u001b[39m accent_function(doc)\n",
      "File \u001b[1;32m~\\.conda\\envs\\skripsitwit\\lib\\site-packages\\scipy\\sparse\\_base.py:771\u001b[0m, in \u001b[0;36mspmatrix.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetnnz()\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(attr \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: lower not found"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(tf_idf_vector)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[0,1]))\n",
    "\n",
    "# from sklearn.cluster import DBSCAN\n",
    "# clusters = DBSCAN(eps=0.6, min_samples=2, metric='precomputed').fit(distance_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "219a7af8-a8bf-4371-ace5-d42198b499fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cosine\n",
    "distance_array = pairwise_distances(tf_idf_vector, metric='cosine')\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "clusters = DBSCAN(eps=0.5, min_samples=10, metric='precomputed').fit(distance_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60dda650-8240-4e9b-ae68-a32f7748d2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 1\n",
      "Estimated number of noise points: 281\n"
     ]
    }
   ],
   "source": [
    "labels = clusters.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "print(\"Estimated number of noise points: %d\" % n_noise_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "800bbaea-ec2e-4a04-8bd1-d7d80d4b97c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cluster = tf_idf_vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e86945a-993e-4193-b6d7-02bb50db379d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels_true must be 1D: shape is (8114, 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHomogeneity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics\u001b[38;5;241m.\u001b[39mhomogeneity_score(data_cluster, labels)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleteness: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics\u001b[38;5;241m.\u001b[39mcompleteness_score(data_cluster, labels)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV-measure: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics\u001b[38;5;241m.\u001b[39mv_measure_score(data_cluster, labels)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\skripsitwit\\lib\\site-packages\\sklearn\\metrics\\cluster\\_supervised.py:564\u001b[0m, in \u001b[0;36mhomogeneity_score\u001b[1;34m(labels_true, labels_pred)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhomogeneity_score\u001b[39m(labels_true, labels_pred):\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;124;03m\"\"\"Homogeneity metric of a cluster labeling given a ground truth.\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \n\u001b[0;32m    501\u001b[0m \u001b[38;5;124;03m    A clustering result satisfies homogeneity if all of its clusters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;124;03m      0.0...\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhomogeneity_completeness_v_measure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_pred\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\.conda\\envs\\skripsitwit\\lib\\site-packages\\sklearn\\metrics\\cluster\\_supervised.py:471\u001b[0m, in \u001b[0;36mhomogeneity_completeness_v_measure\u001b[1;34m(labels_true, labels_pred, beta)\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhomogeneity_completeness_v_measure\u001b[39m(labels_true, labels_pred, \u001b[38;5;241m*\u001b[39m, beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m):\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the homogeneity and completeness and V-Measure scores at once.\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \n\u001b[0;32m    415\u001b[0m \u001b[38;5;124;03m    Those metrics are based on normalized conditional entropy measures of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;124;03m    v_measure_score : V-Measure (NMI with arithmetic mean option).\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 471\u001b[0m     labels_true, labels_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_clusterings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(labels_true) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    474\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m\n",
      "File \u001b[1;32m~\\.conda\\envs\\skripsitwit\\lib\\site-packages\\sklearn\\metrics\\cluster\\_supervised.py:68\u001b[0m, in \u001b[0;36mcheck_clusterings\u001b[1;34m(labels_true, labels_pred)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# input checks\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels_true must be 1D: shape is \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (labels_true\u001b[38;5;241m.\u001b[39mshape,))\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels_pred\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels_pred must be 1D: shape is \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (labels_pred\u001b[38;5;241m.\u001b[39mshape,))\n",
      "\u001b[1;31mValueError\u001b[0m: labels_true must be 1D: shape is (8114, 26)"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(f\"Homogeneity: {metrics.homogeneity_score(data_cluster, labels):.3f}\")\n",
    "print(f\"Completeness: {metrics.completeness_score(data_cluster, labels):.3f}\")\n",
    "print(f\"V-measure: {metrics.v_measure_score(data_cluster, labels):.3f}\")\n",
    "print(f\"Adjusted Rand Index: {metrics.adjusted_rand_score(data_cluster, labels):.3f}\")\n",
    "print(\n",
    "    \"Adjusted Mutual Information:\"\n",
    "    f\" {metrics.adjusted_mutual_info_score(data_cluster, labels):.3f}\"\n",
    ")\n",
    "print(f\"Silhouette Coefficient: {metrics.silhouette_score(distance_array, labels):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "280f9073-bfc4-41d2-8946-71bb673d6b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1, 0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(clusters.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acb5d58a-5032-4095-8023-49f466359d32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({-1: 281, 0: 7833})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(clusters.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8a5abef-fa4d-4d21-a6b2-674ba6509caa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret value `t-SNE-1` for parameter `x`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatterplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mt-SNE-1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mt-SNE-2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclusters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlegend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfull\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdeep\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m sns\u001b[38;5;241m.\u001b[39mmove_legend(p, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupper right\u001b[39m\u001b[38;5;124m\"\u001b[39m, bbox_to_anchor \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.17\u001b[39m, \u001b[38;5;241m1.\u001b[39m), title \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClusters\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\.conda\\envs\\skripsitwit\\lib\\site-packages\\seaborn\\relational.py:742\u001b[0m, in \u001b[0;36mscatterplot\u001b[1;34m(data, x, y, hue, size, style, palette, hue_order, hue_norm, sizes, size_order, size_norm, markers, style_order, legend, ax, **kwargs)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscatterplot\u001b[39m(\n\u001b[0;32m    733\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m    734\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, style\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    739\u001b[0m ):\n\u001b[0;32m    741\u001b[0m     variables \u001b[38;5;241m=\u001b[39m _ScatterPlotter\u001b[38;5;241m.\u001b[39mget_semantics(\u001b[38;5;28mlocals\u001b[39m())\n\u001b[1;32m--> 742\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43m_ScatterPlotter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlegend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlegend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    744\u001b[0m     p\u001b[38;5;241m.\u001b[39mmap_hue(palette\u001b[38;5;241m=\u001b[39mpalette, order\u001b[38;5;241m=\u001b[39mhue_order, norm\u001b[38;5;241m=\u001b[39mhue_norm)\n\u001b[0;32m    745\u001b[0m     p\u001b[38;5;241m.\u001b[39mmap_size(sizes\u001b[38;5;241m=\u001b[39msizes, order\u001b[38;5;241m=\u001b[39msize_order, norm\u001b[38;5;241m=\u001b[39msize_norm)\n",
      "File \u001b[1;32m~\\.conda\\envs\\skripsitwit\\lib\\site-packages\\seaborn\\relational.py:538\u001b[0m, in \u001b[0;36m_ScatterPlotter.__init__\u001b[1;34m(self, data, variables, legend)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, variables\u001b[38;5;241m=\u001b[39m{}, legend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    530\u001b[0m \n\u001b[0;32m    531\u001b[0m     \u001b[38;5;66;03m# TODO this is messy, we want the mapping to be agnostic about\u001b[39;00m\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;66;03m# the kind of plot to draw, but for the time being we need to set\u001b[39;00m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;66;03m# this information so the SizeMapping can use it\u001b[39;00m\n\u001b[0;32m    534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_size_range \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    535\u001b[0m         np\u001b[38;5;241m.\u001b[39mr_[\u001b[38;5;241m.5\u001b[39m, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msquare(mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlines.markersize\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    536\u001b[0m     )\n\u001b[1;32m--> 538\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlegend \u001b[38;5;241m=\u001b[39m legend\n",
      "File \u001b[1;32m~\\.conda\\envs\\skripsitwit\\lib\\site-packages\\seaborn\\_oldcore.py:640\u001b[0m, in \u001b[0;36mVectorPlotter.__init__\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;66;03m# var_ordered is relevant only for categorical axis variables, and may\u001b[39;00m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;66;03m# be better handled by an internal axis information object that tracks\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;66;03m# such information and is set up by the scale_* methods. The analogous\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;66;03m# information for numeric axes would be information about log scales.\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_ordered \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}  \u001b[38;5;66;03m# alt., used DefaultDict\u001b[39;00m\n\u001b[1;32m--> 640\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var, \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_semantic_mappings\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    643\u001b[0m \n\u001b[0;32m    644\u001b[0m     \u001b[38;5;66;03m# Create the mapping function\u001b[39;00m\n\u001b[0;32m    645\u001b[0m     map_func \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmap, plotter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\skripsitwit\\lib\\site-packages\\seaborn\\_oldcore.py:701\u001b[0m, in \u001b[0;36mVectorPlotter.assign_variables\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlong\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 701\u001b[0m     plot_data, variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_variables_longform(\n\u001b[0;32m    702\u001b[0m         data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mvariables,\n\u001b[0;32m    703\u001b[0m     )\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_data \u001b[38;5;241m=\u001b[39m plot_data\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables \u001b[38;5;241m=\u001b[39m variables\n",
      "File \u001b[1;32m~\\.conda\\envs\\skripsitwit\\lib\\site-packages\\seaborn\\_oldcore.py:938\u001b[0m, in \u001b[0;36mVectorPlotter._assign_variables_longform\u001b[1;34m(self, data, **kwargs)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[0;32m    934\u001b[0m \n\u001b[0;32m    935\u001b[0m     \u001b[38;5;66;03m# This looks like a column name but we don't know what it means!\u001b[39;00m\n\u001b[0;32m    937\u001b[0m     err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not interpret value `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` for parameter `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    941\u001b[0m \n\u001b[0;32m    942\u001b[0m     \u001b[38;5;66;03m# Otherwise, assume the value is itself data\u001b[39;00m\n\u001b[0;32m    943\u001b[0m \n\u001b[0;32m    944\u001b[0m     \u001b[38;5;66;03m# Raise when data object is present and a vector can't matched\u001b[39;00m\n\u001b[0;32m    945\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd\u001b[38;5;241m.\u001b[39mDataFrame) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, pd\u001b[38;5;241m.\u001b[39mSeries):\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret value `t-SNE-1` for parameter `x`"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "p = sns.scatterplot(data = df, x = \"t-SNE-1\", y = \"t-SNE-2\", hue = clusters.labels_, legend = \"full\", palette = \"deep\")\n",
    "sns.move_legend(p, \"upper right\", bbox_to_anchor = (1.17, 1.), title = 'Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15812bdd-e01f-4b27-b6b9-b8d54a5d7515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8114x26 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 18349 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1c9b9fb-eed4-4a73-98f8-faf259fb0f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cosine\n",
    "distance_array = pairwise_distances(tf_idf_vector, metric='cosine')\n",
    "\n",
    "from sklearn.cluster import OPTICS\n",
    "clusters = DBSCAN(eps=0.5, min_samples=2, metric='precomputed').fit(distance_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2658777a-0c85-44d1-ad6c-7c2666c9e994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
